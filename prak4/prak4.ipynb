{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737310dd",
   "metadata": {},
   "source": [
    "# Praktikum Visi Komputer\n",
    "## Modul ke-4\n",
    "\n",
    "## Fourier transform, Filter, dan Edge detection\n",
    "\n",
    "Saat kita bekerja dengan gambar/image/citra, bisa saja kita perlu memproses citra seperti mempertajam citra, menggabungkan citra, menggunakan filter. Pemprosesan citra tersebut akan berguna pada proses selanjutnya. Salah satunya seperti pada proses deteksi tepi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80d911",
   "metadata": {},
   "source": [
    "### Fourier transform\n",
    "\n",
    "Sebagian besar pemrosesan yang akan kita terapkan pada citra dan video di OpenCV melibatkan konsep transformasi Fourier / Fourier Transform (FT). Joseph Fourier adalah seorang matematikawan berkebangsaan Prancis yang menemukan dan mempopulerkan banyak konsep matematika abad ke-18. Dia mempelajari bentuk fisika dari panas dan memodelkan secara matematika semua hal yang dapat diwakili oleh gelombang fungsi (waveform). Secara khusus, ia mengamati bahwa semua bentuk gelombang hanyalah jumlah dari sinusoida sederhana dari frekuensi yang berbeda.\n",
    "\n",
    "Dengan kata lain, bentuk gelombang yang kita amati di sekitar kita adalah jumlah dari bentuk gelombang yang lain. Konsep ini sangat berguna saat memanipulasi citra karena memungkinkan kita untuk mengidentifikasi wilayah dalam citra di mana terjadi perubahan sinyal (seperti nilai piksel citra) yang banyak, ataupun perubahannya yang tidak terlalu dramatis. Kita kemudian dapat menandai ini sebagai noise atau bisa sebagai region of interest (ROI), bisa sebagai backgroud atau bisa sebagai foreground, dan lainnya. \n",
    "\n",
    "OpenCV mengimplementasikan sejumlah algoritma yang memungkinkan kita untuk memproses citra dan memahami data yang terkandung di dalamnya. Hal tersebut juga diimplementasikan kembali pada NumPy sehingga dapat memudahkan kita dalam memproses citra/image. NumPy memiliki modul/package Fast Fourier Transform (FFT), yang berisi method fft2. Method ini memungkinkan kita untuk menghitung transformasi Fourier diskrit/ Discrete Fourier Transform (DFT) dari suatu citra/image.\n",
    "\n",
    "Transformasi Fourier (FT) adalah dasar dari banyak algoritma yang digunakan untuk pemprosesan citra, seperti deteksi tepi (edge detection) atau deteksi garis dan bentuk. Sebelumnya, mari kita lihat dua konsep yang berhubungan dengan transformasi Fourier dalam membentuk dasar dari operasi pemrosesan citra, yaitu HPF dan LPF.\n",
    "\n",
    "#### HPF dan LPF\n",
    "\n",
    "HPF (High-Pass Filter) adalah filter yang memeriksa kawasan citra dan meningkatkan intensitas piksel tertentu berdasarkan perbedaan intensitas piksel di sekitarnya. High-Pass Filter (HPF) digunakan untuk mempertahankan titik yang berbeda dengan titik-titik tetangganya (proses deteksi tepi). HPF merupakan suatu bentuk filter yang mengambil data pada frekuensi tinggi dan membuang data pada frekuensi rendah.\n",
    "\n",
    "Contohnya pada kernel berikut:\n",
    "\n",
    "[![QJZJ1z.png](https://i.im.ge/2021/09/09/QJZJ1z.png)](https://im.ge/i/QJZJ1z)\n",
    "\n",
    "*Kernel adalah sekumpulan bobot yang diterapkan ke suatu kawasan dari sumber citra untuk menghasilkan satu piksel dalam gambar tujuan. Misalnya, jika kita memanggil fungsi OpenCV dengan parameter untuk menentukan ukuran kernel atau ksize dari 7, ini berarti bahwa 49 (7 x 7) piksel sumber dipertimbangkan saat menghasilkan setiap piksel tujuan. Kita dapat menganggap kernel sebagai sepotong kaca buram bergerak di atas sumber citra dan membiarkan campuran cahaya tersebar melewatinya.*\n",
    "\n",
    "Kernel sebelumnya memberi kita perbedaan rata-rata dalam intensitas antara piksel pusat dan semua tetangga horizontal terdekatnya. Jika sebuah piksel menonjol dari piksel sekitarnya, nilai yang dihasilkan akan tinggi. Jenis kernel ini disebut filter high-boost, yang merupakan jenis HPF, dan sangat efektif dalam deteksi tepi (edge detection).\n",
    "\n",
    "Ciri-ciri kernel dari HPF adalah nilai-nilainya terdiri dari positif, nol dan negatif, dan jumlah dari semua nilainya sama dengan nol.\n",
    "\n",
    "Low-Pass Filter (LPF) adalah suatu bentuk filter yang mengambil frekuensi rendah dan membuang frekuensi tinggi. LPF digunakan untuk melakukan proses efek blur dan reduksi noise. Ciri-ciri kernel dari LPF adalah semua nilainya positif dan jumlah dari semua nilainya sama dengan satu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fcbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f8f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "kernel_3x3 = np.array([[-1, -1, -1],\n",
    "                        [-1, 8, -1],\n",
    "                        [-1, -1, -1]])\n",
    "\n",
    "kernel_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
    "                        [-1, 1, 2, 1, -1],\n",
    "                        [-1, 2, 4, 2, -1],\n",
    "                        [-1, 1, 2, 1, -1],\n",
    "                        [-1, -1, -1, -1, -1]])\n",
    "\n",
    "#download gambar di: https://i.im.ge/2021/09/09/QpEGLF.jpg\n",
    "img = cv2.imread(\"gambar/statue_small.jpg\", 0)\n",
    "\n",
    "#konvolusi adalah operasi matematika pada dua fungsi yang menghasilkan fungsi ketiga \n",
    "#yang menyatakan bagaimana bentuk yang satu diubah oleh yang lain.\n",
    "#NumPy juga memiliki method convolve tapi untuk one-dimensional array\n",
    "#method convolve pada ndimage dari SciPy dapat digunakan pada multidimensional array\n",
    "k3 = ndimage.convolve(img, kernel_3x3)\n",
    "k5 = ndimage.convolve(img, kernel_5x5)\n",
    "\n",
    "#Gaussian blur (juga dikenal sebagai Gaussian smoothing) adalah hasil dari pengaburan gambar \n",
    "#oleh fungsi Gaussian. Ini adalah efek yang banyak digunakan dalam software grafis, \n",
    "#biasanya untuk mengurangi noise gambar dan mengurangi detail.\n",
    "#Gaussian blur merupakan salah satu jenis dari LPF\n",
    "blurred = cv2.GaussianBlur(img, (17,17), 0)\n",
    "g_hpf = img - blurred\n",
    "\n",
    "cv2.imshow(\"3x3\", k3)\n",
    "cv2.imshow(\"5x5\", k5)\n",
    "cv2.imshow(\"blurred\", blurred)\n",
    "cv2.imshow(\"g_hpf\", g_hpf)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd996b5",
   "metadata": {},
   "source": [
    "### Smoothing and Blurring\n",
    "\n",
    "*Blurring* atau citra kabur terjadi saat kita biasanya mengambil foto menggunakan kamera namun hasilnya tidak fokus atau jelas. Pada citra yang blur biasanya bagian yang tajam tidak muncul disebabkan citra bercampur dengan intensitas piksel di sekitarnya. Walau citra yang kurang jelas atau tidak fokus ini tidak diinginkan pada hasil fotografi, namun ternyata citra tersebut sangat berguna dalam pemprosesan citra.\n",
    "Bahkan sebenarnya, beberapa fungsi pada pemprosesan citra dan visi komputer seperti thresholding dan deteksi tepi, dapat berfungsi dengan lebih baik pada citra yang sebelumnya telah di-smooth atau di-blur.\n",
    "\n",
    "#### Averaging\n",
    "Proses 'averaging' aan menggunakan jendela geser k x k di atas citra, di mana k selalu bernilai ganjil (agar ada piksel titik tengahnya). Jendela ini akan bergeser dari kiri-ke-kanan dan dari atas-ke-bawah. Piksel pada bagian tengah matrik ini akan ditetapkan sebagai rata-rata (*average*) dari semua piksel yang mengelilinginya. Jendela geser ini disebut \"convolution kernel\" atau \"kernel\". \n",
    "\n",
    "Contoh kernel 3x 3 untuk *averaging* adalah:\n",
    "[![averaging](https://i.im.ge/2022/09/11/O4fsZf.averaging.png)](https://im.ge/i/O4fsZf)\n",
    "\n",
    "Nanti anda dapat memperhatikan saat melakukan percobaan, saat ukuran dari kernel bertambah besar, maka citra akan semakin *blurred*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8423b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53e3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"gambar/flower1.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    cv2.blur(img, (3, 3)),\n",
    "    cv2.blur(img, (5, 5)),\n",
    "    cv2.blur(img, (7, 7))])\n",
    "\n",
    "cv2.imshow(\"Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1722b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 1\n",
    "#Silakan bereksperimen dengan citra lain seperti\n",
    "img = cv2.imread(\"gambar/orange.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    cv2.blur(img, (4, 4)),\n",
    "    cv2.blur(img, (6, 6)),\n",
    "    cv2.blur(img, (8, 8))])\n",
    "\n",
    "cv2.imshow(\"Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa954d5",
   "metadata": {},
   "source": [
    "#### Gaussian\n",
    "\n",
    "*Gaussian blurring* sebenarnya mirip dengan *average blurring*. Jika pada *average blurring* menggunakan rata-rata (*mean*) sederhana, namun pada *gaussian blurring* menggunakan rata-rata berpemberat (*weighted mean*) di mana piksel sekelilingnya (*neighborhood*) yang lebih dekat ke titik tengah piksel berkontribusi pemberat (*weight*) lebih banyak kepada nilai rata-ratanya.\n",
    "\n",
    "Contoh kernel 3 x 3 untuk *gaussian blurring* adalah\n",
    "[![gaussian3x3](https://i.im.ge/2022/09/11/O4fglh.gaussian3x3.png)](https://im.ge/i/O4fglh)\n",
    "\n",
    "Citra hasilnya menjadi kurang *blurred* namun lebih natural *blurred*nya, dibandingkan dengan hasil citra blur menggunakan metode average sebelumnya.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb060ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"gambar/flower1.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    cv2.GaussianBlur(image, (3, 3), 0),\n",
    "    cv2.GaussianBlur(image, (5, 5), 0),\n",
    "    cv2.GaussianBlur(image, (7, 7), 0)])\n",
    "\n",
    "cv2.imshow(\"Gaussian Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01e7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 2\n",
    "#Silakan bereksperimen dengan citra lainnya\n",
    "image = cv2.imread(\"gambar/orange.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    cv2.GaussianBlur(image, (3, 3), 0),\n",
    "    cv2.GaussianBlur(image, (5, 5), 0),\n",
    "    cv2.GaussianBlur(image, (7, 7), 0)])\n",
    "\n",
    "cv2.imshow(\"Gaussian Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3fe58b",
   "metadata": {},
   "source": [
    "#### Median\n",
    "\n",
    "*Median blurring* merupakan metode blur yang sering digunakan untuk menghilangkan *salt-and-pepper noise*. *Salt-and-pepper noise* ini seperti anda tidak sengaja memercikkan garam dan merica ke atas suatu foto. Jadi metode *median blur* ini dapat menghilangkan noda garam dan merica dari atas foto tersebut.\n",
    "\n",
    "Sama seperti metode blur lainnya, untuk menggunakan median blur kita perlu definisikan kernel dengan ukuran k. Jika pada metode *average* kita mengganti titik tengah piksel dengan rata-rata sekelilingnya, maka pada *median blur* kita mengganti titik tengah piksel dengan nilai median dari sekelilingnya. Sehingga *median blurring* efektif untuk menghilangkan *salt-and-pepper noise* dari citra karena setiap titik tengah piksel akan digantikan dengan intensitas piksel lainnya yang wujud pada citra.\n",
    "\n",
    "Apabila anda melihat hasil dari median blur, semakin besar kernel maka noise dan detail semakin lama semakin hilang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5d92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download image di https://i.im.ge/2022/09/11/O4HTZx.noise.jpg\n",
    "image = cv2.imread(\"gambar/noise.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    image,\n",
    "    cv2.medianBlur(image, 3),\n",
    "    cv2.medianBlur(image, 5),\n",
    "    cv2.medianBlur(image, 7)])\n",
    "\n",
    "cv2.imshow(\"Median Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 3\n",
    "#Silakan bereksperimen dengan citra lainnya seperti\n",
    "#https://i.im.ge/2022/09/11/O4zVOp.median.png\n",
    "#https://i.im.ge/2022/09/11/O4HXXa.noise1.jpg\n",
    "#https://i.im.ge/2022/09/11/O4Hrby.noise1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"gambar/taj.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    image,\n",
    "    cv2.medianBlur(image, 3),\n",
    "    cv2.medianBlur(image, 5),\n",
    "    cv2.medianBlur(image, 7)])\n",
    "\n",
    "cv2.imshow(\"Median Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619b852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"gambar/pantai.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    image,\n",
    "    cv2.medianBlur(image, 3),\n",
    "    cv2.medianBlur(image, 5),\n",
    "    cv2.medianBlur(image, 7)])\n",
    "\n",
    "cv2.imshow(\"Median Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6071d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"gambar/buah.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    image,\n",
    "    cv2.medianBlur(image, 3),\n",
    "    cv2.medianBlur(image, 5),\n",
    "    cv2.medianBlur(image, 7)])\n",
    "\n",
    "cv2.imshow(\"Median Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55580a",
   "metadata": {},
   "source": [
    "#### Bilateral\n",
    "\n",
    "Metode blurring yang telah dijelaskan sebelum ini memang dapat membuat kabur dan menghilangkan noise serta detil pada citra, namun dalam prosesnya juga dapat menghilangkan tepi daripada suatu citra. Oleh karena itu, untuk mengurangi noise namun tepi tetap ada, maka kita dapat menggunakan *bilateral blurring*. \n",
    "\n",
    "*Bilateral blurring* menyelesaikan masalah ini dengan memperkenalkan dua distribusi Gaussian. Fungsi distribusi Gaussian pertama hanya mempertimbangkan tetangga sekelilingnya (*spatial neighbors*) atau dengan kata lain piksel yang muncul dekat dan bersama-sama pada koordinat (x, y) dari citra. Fungsi distribusi Gaussian kedua akan memodelkan intensitas piksel dari sekelilingnya, untuk memastikan hanya piksel dengan intensitas mirip yang akan dimasukkan ke proses komputasi blur nantinya.\n",
    "\n",
    "Secara umum, hasil *bilateral blurring* dapat mengurangi noise dengan tetap mempertahankan tepi. Namun sayangnya metode ini bekerja lebih lambat dibandingkan dengan metode average, gaussian dan median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ac61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download image di https://i.im.ge/2022/09/11/O4HTZx.noise.jpg\n",
    "image = cv2.imread(\"gambar/noise.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurred = np.hstack([\n",
    "    image,\n",
    "    cv2.bilateralFilter(image, 5, 21, 21),\n",
    "    cv2.bilateralFilter(image, 7, 31, 31),\n",
    "    cv2.bilateralFilter(image, 9, 41, 41)])\n",
    "\n",
    "cv2.imshow(\"Bilateral Blurred images\", blurred)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b10251",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "\n",
    "Tepi memainkan peran utama dalam penglihatan manusia dan komputer. Kita sebagai manusia dapat dengan mudah mengenali banyak jenis objek dan posenya hanya dengan melihat siluet backlit atau sketsa kasar. Tepi membantu kita dalam mengekstrak informasi, mengenali objek, dan memulihkan geometri dan sudut pandang. Tepi biasanya muncul karena diskontinuitas dalam permukaan normal, kedalaman, warna permukaan, dan iluminasi.\n",
    "\n",
    "Tujuan dari deteksi tepi adalah untuk mengidentifikasi perubahan mendadak (diskontinuitas) pada suatu citra. Secara intuitif, sebagian besar informasi semantik dan bentuk dari citra dapat dikodekan pada tepinya.\n",
    "\n",
    "[![edge](https://i.im.ge/2022/09/10/OnPxSK.edge.png)](https://im.ge/i/OnPxSK)\n",
    "\n",
    "OpenCV menyediakan banyak filter pencarian tepi, seperti `Laplacian`, `Sobel`, dan `Scharr`. Filter ini seharusnya mengubah daerah non-tepi menjadi hitam dan mengubah daerah tepi menjadi warna putih atau warna jenuh. Namun, filter tersebut cenderung salah dalam mengidentifikasi kebisingan (noise) sebagai tepi. Cacat ini dapat dikurangi dengan mengaburkan gambar sebelum mencoba menemukan tepinya. OpenCV juga menyediakan banyak filter blur, termasuk `blur` (simple average), `medianBlur`, dan `GaussianBlur`. Argumen untuk filter pencarian tepi dan pengaburan/blur bervariasi tetapi selalu menyertakan ksize, yaitu bilangan bulat ganjil yang mewakili lebar dan tinggi (dalam piksel) dari kernel filter.\n",
    "\n",
    "Untuk pengaburan/blur, kita akan menggunakan `medianBlur`, yang efektif menghilangkan noise pada video digital, terutama pada gambar berwarna. Untuk pencarian tepi, mari gunakan `Laplacian`, yang menghasilkan garis tepi tebal, terutama pada gambar skala abu-abu. Setelah menerapkan `medianBlur`, tetapi sebelum menerapkan `Laplacian`, kita harus mengubah gambar dari BGR menjadi grayscale.\n",
    "\n",
    "Setelah kita mendapatkan hasil `Laplacian`, kita dapat membalikkannya untuk mendapatkan tepi hitam pada latar belakang putih. Kemudian, kita dapat menormalkannya (sehingga nilainya berkisar dari 0 hingga 1) dan kemudian mengalikannya dengan gambar sumber untuk menggelapkan tepinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea802c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d48769",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"gambar/statue_small.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "blurredSrc = cv2.medianBlur(img, 7) \n",
    "graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize = 5)\n",
    "\n",
    "normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)\n",
    "channels = cv2.split(img)\n",
    "for channel in channels:\n",
    "    channel[:] = channel * normalizedInverseAlpha\n",
    "\n",
    "    cv2.merge(channels, img)\n",
    "\n",
    "cv2.imshow(\"Median dan Laplacia\", graySrc)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457b21e",
   "metadata": {},
   "source": [
    "### Deteksi tepi dengan Canny\n",
    "\n",
    "Deteksi tepi dengan menggunakan Laplacian masih menimbulkan banyak noise. Untuk mengatasi masalah tersebut, kita dapat menggunakan Canny edge detector. Fungsi Canny ini sangat popular tidak hanya karena efektif, namun juga sangat sederhana penggunaannya pada OpenCV yaitu hanya satu baris saja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4feac12",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mf:\\00-KULIAH\\5_SEMESTER\\VISKOM\\Prak\\prak4\\prak4.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mgambar/statue_small.jpg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m\"\u001b[39m\u001b[39mcanny.jpg\u001b[39m\u001b[39m\"\u001b[39m, cv2\u001b[39m.\u001b[39mCanny(img, \u001b[39m200\u001b[39m, \u001b[39m300\u001b[39m)) \u001b[39m# Canny in one line!\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m\"\u001b[39;49m\u001b[39mcanny\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mcanny.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n>  - imshow() missing required argument 'mat' (pos 2)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"gambar/statue_small.jpg\", 0)\n",
    "cv2.imwrite(\"canny.jpg\", cv2.Canny(img, 200, 300)) # Canny in one line!\n",
    "cv2.imshow(\"canny\", cv2.imread(\"canny.jpg\"))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7aefa",
   "metadata": {},
   "source": [
    "Hasilnya menampilkan edge/tepi yang sangat jelas sekali. Walaupun penggunaanya hanya 1 baris saja, namun sebenarnya algoritma Canny edge detection ini kompleks. Terdapat 5 langkah proses pada Canny edge detection:\n",
    "1. Denoise citra dengan filter Gaussian\n",
    "2. Hitung gradientnya\n",
    "3. Terapkan non-maximum suppression (NMS) pada tepinya. Ini bermakna, algoritma Canny memilih tepi terbaik dari suatu set tepi yang tumpang tindih. \n",
    "4. Terapkan ambang ganda (double threshold) ke semua tepi yang terdeteksi untuk menghilangkan False Positive.\n",
    "5. Analisis semua tepi dan hubungannya satu sama lain untuk menjaga tepi yang sebenarnya dan membuang tepi yang lemah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af2c180b",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:801: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mf:\\00-KULIAH\\5_SEMESTER\\VISKOM\\Prak\\prak4\\prak4.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Latihan 4\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#Silakan bereksperimen dengan gambar lainnya (bebas) untuk melakukan deteksi tepi menggunakan Canny\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mgambar/orange.jpg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimwrite(\u001b[39m\"\u001b[39;49m\u001b[39mcanny1.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m, cv2\u001b[39m.\u001b[39;49mCanny(img, \u001b[39m200\u001b[39;49m, \u001b[39m300\u001b[39;49m)) \u001b[39m# Canny in one line!\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mcanny1\u001b[39m\u001b[39m\"\u001b[39m, cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mcanny1.jpg\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/00-KULIAH/5_SEMESTER/VISKOM/Prak/prak4/prak4.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:801: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "#Latihan 4\n",
    "#Silakan bereksperimen dengan gambar lainnya (bebas) untuk melakukan deteksi tepi menggunakan Canny\n",
    "img = cv2.imread(\"gambar/orange.jpg\", 0)\n",
    "cv2.imwrite(\"canny1.jpg\", cv2.Canny(img, 200, 300)) # Canny in one line!\n",
    "cv2.imshow(\"canny1\", cv2.imread(\"canny1.jpg\"))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8b99d",
   "metadata": {},
   "source": [
    "### Deteksi Kontur (contour detection)\n",
    "\n",
    "Tugas penting lainnya dalam visi komputer adalah deteksi kontur. Kita ingin mendeteksi kontur atau garis luar subjek yang terdapat dalam bingkai gambar atau video. Dan hasil dari deteksi kontur juga digunakan pada operasi lainnya. Operasi-operasi ini diantaranya menghitung bounding polygon, perkiraan bentuk, dan menghitung region of interest (ROI). ROI dapat menyederhanakan interaksi dengan data citra sebab wilayah persegi panjang pada NumPy mudah ditentukan dengan menggunakan irisan array (array slicing). Kita akan banyak menggunakan deteksi kontur dan ROI pada bahasan mengenai deteksi objek (termasuk deteksi wajah) dan pelacakan objek.\n",
    "\n",
    "Berikut contoh sederhana dari kontur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b982155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((200, 200), dtype=np.uint8)\n",
    "img[50:150, 50:150] = 255\n",
    "\n",
    "ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "img = cv2.drawContours(color, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow(\"contours\", color)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bde2f",
   "metadata": {},
   "source": [
    "Menentukan kontur pada persegi sangat mudah (sesuai contoh di atas). Namun menentukan kontur pada bentuk irregular, miring dan berotasi adalah challenging. \n",
    "\n",
    "#### Bounding box, minimum area rectangle, dan minimum enclosing circle\n",
    "Dalam aplikasi kehidupan nyata, kita akan sering membuat *the bounding box of the subject*, *its minimum enclosing rectangle*, dan *its enclosing circle*. Fungsi cv2.findContours, bersama dengan beberapa utilitas OpenCV lainnya, membuat pekerjaan ini menjadi sangat mudah untuk dilakukan. \n",
    "\n",
    "Seperti pada contoh program di bawah. Pertama, kode berikut membaca gambar dari file, mengubahnya menjadi citra abu-abu, menerapkan ambang batas (threshold) ke citra skala abu-abu, dan menemukan kontur pada gambar threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b1bec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download gambar di https://i.im.ge/2021/09/10/QJJMsp.jpg\n",
    "img = cv2.pyrDown(cv2.imread(\"gambar/hammer.jpg\", cv2.IMREAD_UNCHANGED))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Lalu untuk setiap kontur, kita dapat menemukan bounding box, minimum enclosing rectangle, \n",
    "#dan minimum enclosing circle\n",
    "for c in contours:\n",
    "    # find bounding box coordinates\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    \n",
    "    # find minimum area\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    # calculate coordinates of the minimum area rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    # normalize coordinates to integers\n",
    "    box = np.int0(box)\n",
    "    # draw contours\n",
    "    cv2.drawContours(img, [box], 0, (0,0, 255), 3)\n",
    "    \n",
    "    # calculate center and radius of minimum enclosing circle\n",
    "    (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "    # cast to integers\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    # draw the circle\n",
    "    img = cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "    \n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82bd9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 5\n",
    "#Gunakan code di atas dan lakukan eksperimen pada gambar sederhana lainnya\n",
    "#Download gambar di https://i.im.ge/2021/09/10/QJJMsp.jpg\n",
    "img = cv2.pyrDown(cv2.imread(\"gambar/taj.jpg\", cv2.IMREAD_UNCHANGED))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Lalu untuk setiap kontur, kita dapat menemukan bounding box, minimum enclosing rectangle, \n",
    "#dan minimum enclosing circle\n",
    "for c in contours:\n",
    "    # find bounding box coordinates\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    \n",
    "    # find minimum area\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    # calculate coordinates of the minimum area rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    # normalize coordinates to integers\n",
    "    box = np.int0(box)\n",
    "    # draw contours\n",
    "    cv2.drawContours(img, [box], 0, (0,0, 255), 3)\n",
    "    \n",
    "    # calculate center and radius of minimum enclosing circle\n",
    "    (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "    # cast to integers\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    # draw the circle\n",
    "    img = cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "    \n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86912801",
   "metadata": {},
   "source": [
    "#### Convex contours dan algoritma Douglas-Peucker algorithm\n",
    "\n",
    "Saat bekerja dengan kontur, kita mungkin menemukan subjek dengan beragam bentuk, termasuk bentuk cembung/convex. Bentuk convex adalah bentuk di mana tidak ada dua titik dalam bentuk ini yang garis penghubungnya keluar dari keliling bentuk itu sendiri.\n",
    "\n",
    "Salah satu fasilitas yang ditawarkan OpenCV untuk menghitung perkiraan batas poligon suatu bentuk adalah `cv2.approxPolyDP`. Fungsi ini membutuhkan tiga parameter:\n",
    "- Sebuah kontur.\n",
    "- Nilai epsilon yang mewakili perbedaan maksimum antara kontur asli dan poligon yang didekati (semakin rendah nilainya, semakin dekat nilai perkiraan dengan kontur asli).\n",
    "- Boolean flag. Jika bernilai True, itu menandakan bahwa poligon tertutup.\n",
    "\n",
    "Anda mungkin bertanya-tanya, mengapa kita masih memerlukan approximate polygon, padahal sebelumnya kita sudah memiliki kontur. Jawabannya terkait dengan bentuk poligon yang merupakan kumpulan garis lurus. Banyak tugas computer vision menjadi lebih sederhana jika kita dapat mendefinisikan poligon sehingga poligon membatasi wilayah untuk manipulasi dan pemrosesan lebih lanjut.\n",
    "\n",
    "Mari kita gabungkan kontur asli, kontur approximate poligon, dan convex hull menjadi satu gambar untuk mengamati perbedaan di antara mereka. Untuk mempermudah, kita akan menggambar kontur di atas latar belakang hitam sehingga subjek aslinya tidak terlihat tetapi konturnya tampak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d07df90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.pyrDown(cv2.imread(\"gambar/hammer.jpg\", cv2.IMREAD_UNCHANGED))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "black = np.zeros_like(img)\n",
    "\n",
    "for cnt in contours:\n",
    "    epsilon = 0.01 * cv2.arcLength(cnt,True)\n",
    "    approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    cv2.drawContours(black, [cnt], -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(black, [approx], -1, (255, 255, 0), 2)\n",
    "    cv2.drawContours(black, [hull], -1, (0, 0, 255), 2)\n",
    "    \n",
    "cv2.imshow(\"hull\", black)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11736ef",
   "metadata": {},
   "source": [
    "### Deteksi garis, lingkaran, dan bentuk lainnya \n",
    "\n",
    "Selain dari deteksi tepi dan deteksi kontur, deteksi garis dan bentuk juga berjalan beriringan. Teori di balik deteksi garis dan bentuk memiliki landasan dalam teknik yang disebut transformasi Hough, ditemukan oleh Richard Duda dan Peter Hart, yang memperluas pekerjaan yang dilakukan oleh Paul Hough pada awal 1960-an.\n",
    "\n",
    "Suatu garis dapat direpresentasikan dalam persamaan y = mx + c ataupun dalam bentuk parameter seperti persamaan r = xcosθ + ysinθ di mana r merupakan jarak tegak lurus dari titik asal ke garis, dan θ merupakan sudut yang terbentuk dari garis tegak lurus tersebut dengan sumbu x (horizontal) dihitung secara berlawanan arah jarum jam.\n",
    "[![houghline](https://i.im.ge/2022/09/10/OnNBpK.houghline.png)](https://im.ge/i/OnNBpK)\n",
    "\n",
    "Pertama-tama, kita coba lakukan deteksi garis. Kita dapat melakukan ini dengan fungsi `HoughLines` atau fungsi `HoughLinesP`. Yang pertama menggunakan transformasi Hough yang standar, sedangkan yang kedua menggunakan transformasi Hough probabilistik. Versi probabilistik disebut demikian karena hanya menganalisis subset dari titik-titik gambar dan memperkirakan probabilitas bahwa semua titik ini termasuk dalam garis yang sama. Implementasi ini merupakan versi optimal dari transformasi Hough standar. HoughLinesP diimplementasikan sehingga mengembalikan dua titik akhir dari setiap segmen garis yang terdeteksi, sedangkan HoughLines diimplementasikan sehingga mengembalikan representasi setiap garis sebagai satu titik dan sudut, tanpa informasi tentang titik akhir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25164ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate HoughLine\n",
    "# Download gambar di https://i.im.ge/2022/09/10/OnU3nh.img7.png\n",
    "img = cv2.imread('gambar/img7.png')\n",
    "\n",
    "# Convert the img to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Canny bukanlah kewajiban, tetapi gambar yang telah di-denoise dan hanya memiliki tepi adalah \n",
    "#sumber ideal untuk transformasi Hough, jadi hal ini akan sering dijumpai.\n",
    "# Apply edge detection method on the image\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# This returns an array of r and theta values\n",
    "minLineLength = 100  #panjang garis minimal yang akan terdeteksi, silakan bereksperimen\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, minLineLength)\n",
    "\n",
    "# The below for loop runs till r and theta values\n",
    "# are in the range of the 2d array\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    # Stores the value of cos(theta) in a\n",
    "    a = np.cos(theta)\n",
    "\n",
    "    # Stores the value of sin(theta) in b\n",
    "    b = np.sin(theta)\n",
    "\n",
    "    # x0 stores the value rcos(theta)\n",
    "    x0 = a*r\n",
    "\n",
    "    # y0 stores the value rsin(theta)\n",
    "    y0 = b*r\n",
    "\n",
    "    # x1 stores the rounded off value of (rcos(theta)-1000sin(theta))\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "\n",
    "    # y1 stores the rounded off value of (rsin(theta)+1000cos(theta))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "\n",
    "    # x2 stores the rounded off value of (rcos(theta)+1000sin(theta))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "\n",
    "    # y2 stores the rounded off value of (rsin(theta)-1000cos(theta))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    # cv2.line draws a line in img from the point(x1,y1) to (x2,y2).\n",
    "    # (0,0,255) denotes the colour of the line to be\n",
    "    # drawn. In this case, it is red.\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# All the changes made in the input image are finally\n",
    "# written on a new image or can be shown directly\n",
    "#cv2.imwrite('gambar/linesDetected.jpg', img)\n",
    "cv2.imshow(\"Lines detected HoughLine\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c770371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 6\n",
    "#Silakan bereksperimen dengan gambar lainnya (bebas) untuk melakukan deteksi line\n",
    "# Python program to illustrate HoughLine\n",
    "# Download gambar di https://i.im.ge/2022/09/10/OnU3nh.img7.png\n",
    "img = cv2.imread('gambar/img8.png')\n",
    "\n",
    "# Convert the img to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Canny bukanlah kewajiban, tetapi gambar yang telah di-denoise dan hanya memiliki tepi adalah \n",
    "#sumber ideal untuk transformasi Hough, jadi hal ini akan sering dijumpai.\n",
    "# Apply edge detection method on the image\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# This returns an array of r and theta values\n",
    "minLineLength = 100  #panjang garis minimal yang akan terdeteksi, silakan bereksperimen\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, minLineLength)\n",
    "\n",
    "# The below for loop runs till r and theta values\n",
    "# are in the range of the 2d array\n",
    "for r_theta in lines:\n",
    "    arr = np.array(r_theta[0], dtype=np.float64)\n",
    "    r, theta = arr\n",
    "    # Stores the value of cos(theta) in a\n",
    "    a = np.cos(theta)\n",
    "\n",
    "    # Stores the value of sin(theta) in b\n",
    "    b = np.sin(theta)\n",
    "\n",
    "    # x0 stores the value rcos(theta)\n",
    "    x0 = a*r\n",
    "\n",
    "    # y0 stores the value rsin(theta)\n",
    "    y0 = b*r\n",
    "\n",
    "    # x1 stores the rounded off value of (rcos(theta)-1000sin(theta))\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "\n",
    "    # y1 stores the rounded off value of (rsin(theta)+1000cos(theta))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "\n",
    "    # x2 stores the rounded off value of (rcos(theta)+1000sin(theta))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "\n",
    "    # y2 stores the rounded off value of (rsin(theta)-1000cos(theta))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    # cv2.line draws a line in img from the point(x1,y1) to (x2,y2).\n",
    "    # (0,0,255) denotes the colour of the line to be\n",
    "    # drawn. In this case, it is red.\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# All the changes made in the input image are finally\n",
    "# written on a new image or can be shown directly\n",
    "#cv2.imwrite('gambar/linesDetected.jpg', img)\n",
    "cv2.imshow(\"Lines detected HoughLine\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e008df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate HoughLineP\n",
    "# Download gambar di https://i.im.ge/2022/09/10/OnU3nh.img7.png\n",
    "img = cv2.imread('gambar/img7.png')\n",
    "\n",
    "# Convert the img to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use canny edge detection\n",
    "edges = cv2.Canny(gray,50,150,apertureSize=3)\n",
    " \n",
    "# Apply HoughLinesP method to\n",
    "# to directly obtain line end points\n",
    "lines_list =[]\n",
    "lines = cv2.HoughLinesP(\n",
    "            edges, # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            threshold=100, # Min number of votes for valid line\n",
    "            minLineLength=100, # Min allowed length of line\n",
    "            maxLineGap=10 # Max allowed gap between line for joining them\n",
    "            )\n",
    " \n",
    "# Iterate over points\n",
    "for points in lines:\n",
    "      # Extracted points nested in the list\n",
    "    x1,y1,x2,y2=points[0]\n",
    "    # Draw the lines joing the points\n",
    "    # On the original image\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    # Maintain a simples lookup list for points\n",
    "    lines_list.append([(x1,y1),(x2,y2)])\n",
    "\n",
    "# All the changes made in the input image are finally\n",
    "# written on a new image or can be shown directly\n",
    "#cv2.imwrite('gambar/linesDetected1.jpg', img)\n",
    "cv2.imshow(\"Lines detected using HoughLineP\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e066a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 7\n",
    "#Silakan bereksperimen dengan gambar lainnya (bebas) untuk melakukan deteksi line\n",
    "# Python program to illustrate HoughLineP\n",
    "# Download gambar di https://i.im.ge/2022/09/10/OnU3nh.img7.png\n",
    "img = cv2.imread('gambar/img8.png')\n",
    "\n",
    "# Convert the img to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use canny edge detection\n",
    "edges = cv2.Canny(gray,50,150,apertureSize=3)\n",
    " \n",
    "# Apply HoughLinesP method to\n",
    "# to directly obtain line end points\n",
    "lines_list =[]\n",
    "lines = cv2.HoughLinesP(\n",
    "            edges, # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            threshold=100, # Min number of votes for valid line\n",
    "            minLineLength=100, # Min allowed length of line\n",
    "            maxLineGap=10 # Max allowed gap between line for joining them\n",
    "            )\n",
    " \n",
    "# Iterate over points\n",
    "for points in lines:\n",
    "      # Extracted points nested in the list\n",
    "    x1,y1,x2,y2=points[0]\n",
    "    # Draw the lines joing the points\n",
    "    # On the original image\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    # Maintain a simples lookup list for points\n",
    "    lines_list.append([(x1,y1),(x2,y2)])\n",
    "\n",
    "# All the changes made in the input image are finally\n",
    "# written on a new image or can be shown directly\n",
    "#cv2.imwrite('gambar/linesDetected1.jpg', img)\n",
    "cv2.imshow(\"Lines detected using HoughLineP\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f530359",
   "metadata": {},
   "source": [
    "OpenCV juga memiliki fungsi untuk mendeteksi lingkaran yang bernama `HoughCircles`. Cara kerjanya mirip dengan HoughLines, bedanya pada circle ada tambahan parameter lainnya. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "418c49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download gambar di https://i.im.ge/2021/09/10/QJJlmm.jpg\n",
    "planets = cv2.imread('gambar/planet_glow.jpg')\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "gray_img = cv2.medianBlur(gray_img, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(gray_img,cv2.HOUGH_GRADIENT,1,120, param1=100,param2=30,minRadius=0,maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(planets,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(planets,(i[0],i[1]),2,(0,0,255),3)\n",
    "    \n",
    "cv2.imwrite(\"gambar/planets_circles.jpg\", planets)\n",
    "cv2.imshow(\"HoughCircles\", planets)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b2c2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latihan 8\n",
    "#Silakan bereksperimen dengan gambar lainnya (bebas) untuk melakukan deteksi circle\n",
    "#Download gambar di https://i.im.ge/2021/09/10/QJJlmm.jpg\n",
    "planets = cv2.imread('gambar/planet_glow1.jpg')\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "gray_img = cv2.medianBlur(gray_img, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(gray_img,cv2.HOUGH_GRADIENT,1,120, param1=100,param2=30,minRadius=0,maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(planets,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(planets,(i[0],i[1]),2,(0,0,255),3)\n",
    "    \n",
    "cv2.imwrite(\"gambar/planets_circles1.jpg\", planets)\n",
    "cv2.imshow(\"HoughCircles1\", planets)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72c825",
   "metadata": {},
   "source": [
    "Implementasi OpenCV dari transformasi Hough terbatas pada deteksi garis dan lingkaran. Namun, kita sebenarnya dapat melakukan deteksi bentuk secara umum dengan `approxPolyDP`. Fungsi ini memungkinkan pendekatan poligon, jadi jika gambar Anda berisi poligon, mereka akan dideteksi secara akurat melalui penggunaan gabungan `cv2.findContours` dan `cv2.approxPolyDP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1755bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] original, num_pts=951\n"
     ]
    }
   ],
   "source": [
    "import imutils\n",
    "\n",
    "# Python program to illustrate approxPolyDP\n",
    "# Download gambar di https://i.im.ge/2022/09/10/Onm1mM.box.png\n",
    "img = cv2.imread('gambar/box.png')\n",
    "\n",
    "# convert the image to grayscale and threshold it\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "# find the largest contour in the threshold image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# draw the shape of the contour on the output image, compute the\n",
    "# bounding box, and display the number of points in the contour\n",
    "output = img.copy()\n",
    "cv2.drawContours(output, [c], -1, (0, 255, 0), 3)\n",
    "(x, y, w, h) = cv2.boundingRect(c)\n",
    "text = \"original, num_pts={}\".format(len(c))\n",
    "cv2.putText(output, text, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# show the original contour image\n",
    "print(\"[INFO] {}\".format(text))\n",
    "cv2.imshow(\"Original Contour\", output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f8c2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a896250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] original, num_pts=256\n"
     ]
    }
   ],
   "source": [
    "#Latihan 9\n",
    "#Silakan bereksperimen dengan gambar lainnya (bebas) untuk melakukan deteksi poligon\n",
    "import imutils\n",
    "\n",
    "# Python program to illustrate approxPolyDP\n",
    "# Download gambar di https://i.im.ge/2022/09/10/Onm1mM.box.png\n",
    "img = cv2.imread('gambar/box1.png')\n",
    "\n",
    "# convert the image to grayscale and threshold it\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "# find the largest contour in the threshold image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "# draw the shape of the contour on the output image, compute the\n",
    "# bounding box, and display the number of points in the contour\n",
    "output = img.copy()\n",
    "cv2.drawContours(output, [c], -1, (0, 255, 0), 3)\n",
    "(x, y, w, h) = cv2.boundingRect(c)\n",
    "text = \"original, num_pts={}\".format(len(c))\n",
    "cv2.putText(output, text, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# show the original contour image\n",
    "print(\"[INFO] {}\".format(text))\n",
    "cv2.imshow(\"Original Contour\", output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
